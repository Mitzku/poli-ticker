{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5052635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.8.2-py3-none-any.whl (6.9 MB)\n",
      "     ---------------------------------------- 6.9/6.9 MB 5.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\grego\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
      "     -------------------------------------- 384.9/384.9 kB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\grego\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Using cached trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Downloading exceptiongroup-1.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting async-generator>=1.9\n",
      "  Using cached async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\grego\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Collecting outcome\n",
      "  Using cached outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\grego\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\grego\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\grego\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\grego\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\grego\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\grego\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.3/58.3 kB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: outcome, h11, exceptiongroup, async-generator, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed async-generator-1.10 exceptiongroup-1.1.0 h11-0.14.0 outcome-1.2.0 selenium-4.8.2 trio-0.22.0 trio-websocket-0.9.2 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ab8005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import database\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException    \n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8767d4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\AppData\\Local\\Temp\\ipykernel_12792\\610209268.py:4: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n"
     ]
    }
   ],
   "source": [
    "# specifying path und driver\n",
    "\n",
    "PATH = r\"C:\\Users\\grego\\Dev\\Data and IR\\Abstimmungsverhalten_v2\\chromedriver_win32.exe\"\n",
    "driver = webdriver.Chrome(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05e772db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!!!\n",
      "Found 775 links.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up the webdriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# Navigate to the relevant page\n",
    "driver.get(\"https://www.bundestag.de/abgeordnete/biografien\")\n",
    "\n",
    "# Expand the page to show all MPs\n",
    "button = driver.find_element(By.CSS_SELECTOR, '.bt-link-list[href=\"javascript:void(0);\"]')\n",
    "button.click()\n",
    "time.sleep(5)\n",
    "\n",
    "# Get the links of all MPs\n",
    "try:\n",
    "    links = [i.get_attribute('href') for i in driver.find_elements(By.CSS_SELECTOR, 'a[href^=\"/abgeordnete\"]')]\n",
    "    print('Success!!!')\n",
    "    print(f'Found {len(links)} links.')\n",
    "except Exception as e:\n",
    "    print('Error:', e)\n",
    "\n",
    "# Quit the webdriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "761d4f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\AppData\\Local\\Temp\\ipykernel_12792\\3602561570.py:18: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  bundestags_id   vorname nachname  \\\n",
      "0        861028     Sanae     Abdi   \n",
      "1        857082     Gökay  Akbulut   \n",
      "2        860100  Valentin     Abel   \n",
      "3        860114        Al  Dailami   \n",
      "4        860546      Knut  Abraham   \n",
      "\n",
      "                                           wahlkreis  \\\n",
      "0                              Wahlkreis 093: Köln I   \n",
      "1                            Wahlkreis 275: Mannheim   \n",
      "2         Wahlkreis 268: Schwäbisch Hall – Hohenlohe   \n",
      "3                              Wahlkreis 173: Gießen   \n",
      "4  Wahlkreis 065: Elbe-Elster – Oberspreewald-Lau...   \n",
      "\n",
      "                               facebook_links  \\\n",
      "0       https://www.facebook.com/sanaeabdispd   \n",
      "1  https://www.facebook.com/gokay.akbulut.146   \n",
      "2   https://www.facebook.com/valentinabel.fdp   \n",
      "3                   keine auf Bundestagsseite   \n",
      "4           https://facebook.com/knut.abraham   \n",
      "\n",
      "                              twitter_links                  website_links  \\\n",
      "0     https://twitter.com/abdisanae?lang=de     https://sanae-abdi.spd.de/   \n",
      "1  https://twitter.com/akbulutgokay?lang=de     https://goekay-akbulut.de/   \n",
      "2       https://twitter.com/Valentin_C_Abel  https://www.valentin-abel.de/   \n",
      "3                 keine auf Bundestagsseite      keine auf Bundestagsseite   \n",
      "4                 keine auf Bundestagsseite       https://knut-abraham.de/   \n",
      "\n",
      "                                     instagram_links  \n",
      "0              https://www.instagram.com/sanae_ccaa/  \n",
      "1  https://www.instagram.com/gokayakbulut_mdb_lin...  \n",
      "2  https://www.instagram.com/valentin_christian_a...  \n",
      "3                          keine auf Bundestagsseite  \n",
      "4                          keine auf Bundestagsseite  \n"
     ]
    }
   ],
   "source": [
    "# working with the links liste generated above. we need to filter out the wrong links first before iterating over it and fetching the relevant information\n",
    "\n",
    "regex = 'biografien\\/[a-zA-Z]\\/'\n",
    "\n",
    "falsche_links = []\n",
    "richtige_links = []\n",
    "\n",
    "for lnk in links:\n",
    "    if bool(re.search(regex, lnk)):\n",
    "        richtige_links.append(lnk)\n",
    "    else:\n",
    "        falsche_links.append(lnk)\n",
    "\n",
    "print(len(falsche_links))\n",
    "print(len(richtige_links))\n",
    "\n",
    "#iterating over all  pages and getting the relevant information into df\n",
    "driver = webdriver.Chrome(PATH)\n",
    "\n",
    "#creating the lists that eventually will form the dataframe\n",
    "\n",
    "bundestags_id = []\n",
    "wahlkreis = []\n",
    "nachnamen = []\n",
    "vornamen = []\n",
    "facebook_links = []\n",
    "instagram_links = []\n",
    "twitter_links = []\n",
    "website_links = []\n",
    "\n",
    "\n",
    "# to verify the existence of the element\n",
    "\n",
    "def check_webpage_exists():\n",
    "    try:\n",
    "        driver.find_element(By.CSS_SELECTOR, '.bt-link-extern[title^=\"Homepage\"]')\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_facebook_exists():\n",
    "    try:\n",
    "        driver.find_element(By.CSS_SELECTOR, '.bt-link-extern[title^=\"Facebook\"]')\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_twitter_exists():\n",
    "    try:\n",
    "        driver.find_element(By.CSS_SELECTOR, '.bt-link-extern[title^=\"Twitter\"]')\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_instagram_exists():\n",
    "    try:\n",
    "        driver.find_element(By.CSS_SELECTOR, '.bt-link-extern[title^=\"Instagram\"]')\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_wahlkreis_exists():\n",
    "    try:\n",
    "        driver.find_element(By.CSS_SELECTOR, '.bt-link-intern[title^=\"Wahlkreis\"]')\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "#for test\n",
    "i = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for lnk in richtige_links:\n",
    "    driver.get(lnk)\n",
    "    \n",
    "    try:\n",
    "        #bundestags_id\n",
    "        id_stripped = re.findall(\"\\d+\", lnk)\n",
    "        bundestags_id.append(id_stripped[0])\n",
    "        \n",
    "        # names --- !!!! derzeit sind es nicht immer die korrekten namen. besser sie aus dem namenselement statt dem titel zu ziehen\n",
    "        # NOCH UNKLAR: Welcher Name soll gewählt werden... in welchem Format. Hier scheinen Abweichungen auf der Website, bei manchen wird z.b. (Heilbronn) mitübergeben.\n",
    "        get_title = driver.title\n",
    "        nachnamen.append(re.findall(\"\\w+\", get_title)[-1])\n",
    "        vornamen.append(re.findall(\"\\w+\", get_title)[-2])\n",
    "\n",
    "        # wahlkreis\n",
    "        if check_wahlkreis_exists() == True:\n",
    "            search = driver.find_element(By.CSS_SELECTOR, '.bt-link-intern[title^=\"Wahlkreis\"]').get_attribute('innerHTML')\n",
    "            wahlkreis.append(search)\n",
    "        else: #gibt mir das Bundesland\n",
    "            search = driver.find_element(By.CSS_SELECTOR, '.bt-standard-content.col-sm-6.col-xs-12').get_attribute('innerHTML')\n",
    "            land = re.findall('\\>(.*)\\<', search)\n",
    "            wahlkreis.append('Landesliste:' + str(land))\n",
    "\n",
    "        # links\n",
    "        if check_webpage_exists() == True:\n",
    "            element = driver.find_element(By.CSS_SELECTOR, '.bt-link-extern[title^=\"Homepage\"]')\n",
    "            website_links.append(element.get_attribute('href'))\n",
    "        else:\n",
    "            website_links.append('keine auf Bundestagsseite')\n",
    "\n",
    "        if check_facebook_exists() == True:\n",
    "            element = driver.find_element(By.CSS_SELECTOR, '.bt-link-extern[title^=\"Facebook\"]')\n",
    "            facebook_links.append(element.get_attribute('href'))\n",
    "        else:\n",
    "            facebook_links.append('keine auf Bundestagsseite')\n",
    "\n",
    "        if check_twitter_exists() == True:\n",
    "            element = driver.find_element(By.CSS_SELECTOR, '.bt-link-extern[title^=\"Twitter\"]')\n",
    "            twitter_links.append(element.get_attribute('href'))\n",
    "        else:\n",
    "            twitter_links.append('keine auf Bundestagsseite')\n",
    "            \n",
    "        if check_instagram_exists() == True:\n",
    "            element = driver.find_element(By.CSS_SELECTOR, '.bt-link-extern[title^=\"Instagram\"]')\n",
    "            instagram_links.append(element.get_attribute('href'))\n",
    "        else:\n",
    "            instagram_links.append('keine auf Bundestagsseite')\n",
    "       \n",
    "\n",
    "    except:\n",
    "        #driver.quit()\n",
    "        print('duh!!!!!')\n",
    "        print(error)\n",
    "    \n",
    "     # to test this loop with 5 iterations\n",
    "    i = i + 1\n",
    "    if i == 5:\n",
    "        break\n",
    "\n",
    "df_politiker_selenium = pd.DataFrame()\n",
    "\n",
    "df_politiker_selenium['bundestags_id'] = bundestags_id\n",
    "df_politiker_selenium['vorname'] = vornamen\n",
    "df_politiker_selenium['nachname'] = nachnamen\n",
    "df_politiker_selenium['wahlkreis'] = wahlkreis\n",
    "df_politiker_selenium['facebook_links'] = facebook_links\n",
    "df_politiker_selenium['twitter_links'] = twitter_links\n",
    "df_politiker_selenium['website_links'] = website_links\n",
    "df_politiker_selenium['instagram_links'] = instagram_links\n",
    "\n",
    "print(df_politiker_selenium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b3216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "822617fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\AppData\\Local\\Temp\\ipykernel_12792\\2281796603.py:18: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  bundestags_id   vorname nachname  \\\n",
      "0        861028     Sanae     Abdi   \n",
      "1        857082     Gökay  Akbulut   \n",
      "2        860100  Valentin     Abel   \n",
      "3        860114        Al  Dailami   \n",
      "4        860546      Knut  Abraham   \n",
      "\n",
      "                                           wahlkreis  \\\n",
      "0                              Wahlkreis 093: Köln I   \n",
      "1                            Wahlkreis 275: Mannheim   \n",
      "2         Wahlkreis 268: Schwäbisch Hall – Hohenlohe   \n",
      "3                              Wahlkreis 173: Gießen   \n",
      "4  Wahlkreis 065: Elbe-Elster – Oberspreewald-Lau...   \n",
      "\n",
      "                               facebook_links  \\\n",
      "0       https://www.facebook.com/sanaeabdispd   \n",
      "1  https://www.facebook.com/gokay.akbulut.146   \n",
      "2   https://www.facebook.com/valentinabel.fdp   \n",
      "3                   keine auf Bundestagsseite   \n",
      "4           https://facebook.com/knut.abraham   \n",
      "\n",
      "                              twitter_links                  website_links  \\\n",
      "0     https://twitter.com/abdisanae?lang=de     https://sanae-abdi.spd.de/   \n",
      "1  https://twitter.com/akbulutgokay?lang=de     https://goekay-akbulut.de/   \n",
      "2       https://twitter.com/Valentin_C_Abel  https://www.valentin-abel.de/   \n",
      "3                 keine auf Bundestagsseite      keine auf Bundestagsseite   \n",
      "4                 keine auf Bundestagsseite       https://knut-abraham.de/   \n",
      "\n",
      "                                     instagram_links  \n",
      "0              https://www.instagram.com/sanae_ccaa/  \n",
      "1  https://www.instagram.com/gokayakbulut_mdb_lin...  \n",
      "2  https://www.instagram.com/valentin_christian_a...  \n",
      "3                          keine auf Bundestagsseite  \n",
      "4                          keine auf Bundestagsseite  \n"
     ]
    }
   ],
   "source": [
    "# working with the links liste generated above. we need to filter out the wrong links first before iterating over it and fetching the relevant information\n",
    "\n",
    "regex = 'biografien\\/[a-zA-Z]\\/'\n",
    "\n",
    "falsche_links = []\n",
    "richtige_links = []\n",
    "\n",
    "for lnk in links:\n",
    "    if bool(re.search(regex, lnk)):\n",
    "        richtige_links.append(lnk)\n",
    "    else:\n",
    "        falsche_links.append(lnk)\n",
    "\n",
    "print(len(falsche_links))\n",
    "print(len(richtige_links))\n",
    "\n",
    "#iterating over all  pages and getting the relevant information into df\n",
    "driver = webdriver.Chrome(PATH)\n",
    "\n",
    "#creating the lists that eventually will form the dataframe\n",
    "\n",
    "bundestags_id = []\n",
    "wahlkreis = []\n",
    "nachnamen = []\n",
    "vornamen = []\n",
    "facebook_links = []\n",
    "instagram_links = []\n",
    "twitter_links = []\n",
    "website_links = []\n",
    "\n",
    "\n",
    "# to verify the existence of elements\n",
    "\n",
    "def check_link_exists(link_text):\n",
    "    try:\n",
    "        driver.find_element(By.CSS_SELECTOR, f'.bt-link-extern[title^=\"{link_text}\"]')\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "webpage_exists = check_link_exists(\"Homepage\")\n",
    "facebook_exists = check_link_exists(\"Facebook\")\n",
    "twitter_exists = check_link_exists(\"Twitter\")\n",
    "instagram_exists = check_link_exists(\"Instagram\")\n",
    "wahlkreis_exists = check_link_exists(\"Wahlkreis\")\n",
    "\n",
    "\n",
    "#for test\n",
    "i = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for lnk in richtige_links:\n",
    "    driver.get(lnk)\n",
    "    \n",
    "    try:\n",
    "        #bundestags_id\n",
    "        id_stripped = re.findall(\"\\d+\", lnk)\n",
    "        bundestags_id.append(id_stripped[0])\n",
    "        \n",
    "        # names --- !!!! derzeit sind es nicht immer die korrekten namen. besser sie aus dem namenselement statt dem titel zu ziehen\n",
    "        # NOCH UNKLAR: Welcher Name soll gewählt werden... in welchem Format. Hier scheinen Abweichungen auf der Website, bei manchen wird z.b. (Heilbronn) mitübergeben.\n",
    "        get_title = driver.title\n",
    "        nachnamen.append(re.findall(\"\\w+\", get_title)[-1])\n",
    "        vornamen.append(re.findall(\"\\w+\", get_title)[-2])\n",
    "\n",
    "        # wahlkreis\n",
    "        if check_wahlkreis_exists() == True:\n",
    "            search = driver.find_element(By.CSS_SELECTOR, '.bt-link-intern[title^=\"Wahlkreis\"]').get_attribute('innerHTML')\n",
    "            wahlkreis.append(search)\n",
    "        else: #gibt mir das Bundesland\n",
    "            search = driver.find_element(By.CSS_SELECTOR, '.bt-standard-content.col-sm-6.col-xs-12').get_attribute('innerHTML')\n",
    "            land = re.findall('\\>(.*)\\<', search)\n",
    "            wahlkreis.append('Landesliste:' + str(land))\n",
    "\n",
    "        # links\n",
    "        if check_webpage_exists() == True:\n",
    "            element = driver.find_element(By.CSS_SELECTOR, '.bt-link-extern[title^=\"Homepage\"]')\n",
    "            website_links.append(element.get_attribute('href'))\n",
    "        else:\n",
    "            website_links.append('keine auf Bundestagsseite')\n",
    "\n",
    "        if check_facebook_exists() == True:\n",
    "            element = driver.find_element(By.CSS_SELECTOR, '.bt-link-extern[title^=\"Facebook\"]')\n",
    "            facebook_links.append(element.get_attribute('href'))\n",
    "        else:\n",
    "            facebook_links.append('keine auf Bundestagsseite')\n",
    "\n",
    "        if check_twitter_exists() == True:\n",
    "            element = driver.find_element(By.CSS_SELECTOR, '.bt-link-extern[title^=\"Twitter\"]')\n",
    "            twitter_links.append(element.get_attribute('href'))\n",
    "        else:\n",
    "            twitter_links.append('keine auf Bundestagsseite')\n",
    "            \n",
    "        if check_instagram_exists() == True:\n",
    "            element = driver.find_element(By.CSS_SELECTOR, '.bt-link-extern[title^=\"Instagram\"]')\n",
    "            instagram_links.append(element.get_attribute('href'))\n",
    "        else:\n",
    "            instagram_links.append('keine auf Bundestagsseite')\n",
    "       \n",
    "\n",
    "    except:\n",
    "        #driver.quit()\n",
    "        print('duh!!!!!')\n",
    "        print(error)\n",
    "    \n",
    "     # to test this loop with 5 iterations\n",
    "    i = i + 1\n",
    "    if i == 5:\n",
    "        break\n",
    "\n",
    "df_politiker_selenium = pd.DataFrame()\n",
    "\n",
    "df_politiker_selenium['bundestags_id'] = bundestags_id\n",
    "df_politiker_selenium['vorname'] = vornamen\n",
    "df_politiker_selenium['nachname'] = nachnamen\n",
    "df_politiker_selenium['wahlkreis'] = wahlkreis\n",
    "df_politiker_selenium['facebook_links'] = facebook_links\n",
    "df_politiker_selenium['twitter_links'] = twitter_links\n",
    "df_politiker_selenium['website_links'] = website_links\n",
    "df_politiker_selenium['instagram_links'] = instagram_links\n",
    "\n",
    "print(df_politiker_selenium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d2d170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e59db58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3610539",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkFiltering:\n",
    "    def __init__(self, richtige_links):\n",
    "        self.links = links\n",
    "\n",
    "    def filter_links(self):\n",
    "        regex = 'biografien\\/[a-zA-Z]\\/'\n",
    "        falsche_links = []\n",
    "        richtige_links = []\n",
    "        for lnk in self.links:\n",
    "            if bool(re.search(regex, lnk)):\n",
    "                richtige_links.append(lnk)\n",
    "            else:\n",
    "                falsche_links.append(lnk)\n",
    "        return richtige_links\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae596aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoliticianData:\n",
    "    \n",
    "    def __init__(self, richtige_links, path):\n",
    "        self.links = links\n",
    "        self.path = path\n",
    "        self.driver = webdriver.Chrome(self.path)\n",
    "        self.bundestags_id = []\n",
    "        self.wahlkreis = []\n",
    "        self.nachnamen = []\n",
    "        self.vornamen = []\n",
    "        self.facebook_links = []\n",
    "        self.instagram_links = []\n",
    "        self.twitter_links = []\n",
    "        self.website_links = []\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.driver.quit()\n",
    "        \n",
    "    def filter_links(self, regex='biografien\\/[a-zA-Z]\\/'):\n",
    "        falsche_links = []\n",
    "        richtige_links = []\n",
    "\n",
    "        for lnk in self.links:\n",
    "            if bool(re.search(regex, lnk)):\n",
    "                richtige_links.append(lnk)\n",
    "            else:\n",
    "                falsche_links.append(lnk)\n",
    "\n",
    "        self.links = richtige_links\n",
    "        \n",
    "    def check_webpage_exists(self):\n",
    "        try:\n",
    "            self.driver.find_element(By.CSS_SELECTOR, '.bt-link-extern[title^=\"Homepage\"]')\n",
    "        except NoSuchElementException:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def check_facebook_exists(self):\n",
    "        try:\n",
    "            self.driver.find_element(By.CSS_SELECTOR, '.bt-link-extern[title^=\"Facebook\"]')\n",
    "        except NoSuchElementException:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def check_twitter_exists(self):\n",
    "        try:\n",
    "            self.driver.find_element(By.CSS_SELECTOR, '.bt-link-extern[title^=\"Twitter\"]')\n",
    "        except NoSuchElementException:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def check_instagram_exists(self):\n",
    "        try:\n",
    "            self.driver.find_element(By.CSS_SELECTOR, '.bt-link-extern[title^=\"Instagram\"]')\n",
    "        except NoSuchElementException:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def check_wahlkreis_exists(self):\n",
    "        try:\n",
    "            self.driver.find_element(By.CSS_SELECTOR, '.bt-link-intern[title^=\"Wahlkreis\"]')\n",
    "        except NoSuchElementException:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def get_politician_data(self):\n",
    "        self.driver.get(self.profile_link)\n",
    "        \n",
    "        try:\n",
    "            #bundestags_id\n",
    "            id_stripped = re.findall(\"\\d+\", self.profile_link)\n",
    "            self.bundestags_id = id_stripped[0]\n",
    "\n",
    "            # names --- !!!! derzeit sind es nicht immer die korrekten namen. besser sie aus dem namenselement statt dem titel zu ziehen\n",
    "            # NOCH UNKLAR: Welcher Name soll gewählt werden... in welchem Format. Hier scheinen Abweichungen auf der Website, bei manchen wird z.b. (Heilbronn) mitübergeben.\n",
    "            get_title = self.driver.title\n",
    "            self.nachname = re.findall(\"\\w+\", get_title)[-1]\n",
    "            self.vorname = re.findall(\"\\w+\", get_title)[-2]\n",
    "\n",
    "            # wahlkreis\n",
    "            if self.check_wahlkreis_exists() == True:\n",
    "                search = self.driver.find_element(By.CSS_SELECTOR, '.bt-link-intern[title^=\"Wahlkreis\"]').get_attribute('innerHTML')\n",
    "                self.wahlkreis = search\n",
    "            else: #gibt mir das Bundesland\n",
    "                search = self.driver.find_element(By.CSS_SELECTOR, '.bt-standard-content.col-sm-6.col-xs-12').get_attribute('innerHTML')\n",
    "                land = re.findall('\\>(.*)\\<', search)\n",
    "                self.wahlkreis = 'Landesliste:' + str(land)\n",
    "\n",
    "            # links\n",
    "            if self.check_webpage_exists() == True:\n",
    "                element = self.driver.find_element(By.CSS_SELECTOR, '.bt-link-extern[title^=\"Homepage\"]')\n",
    "                self.website_links = element.get_attribute('href')\n",
    "            else:\n",
    "                self.website_links = 'keine auf Bundestagsseite'\n",
    "\n",
    "            if self.check_facebook_exists() == True:\n",
    "                element = self.driver.find_element(By.CSS_SELECTOR, '.bt-link-extern[title^=\"Facebook\"]')\n",
    "                self.facebook_links = element.get_attribute('href')\n",
    "            else:\n",
    "                self.facebook_links = 'keine auf Bundestagsseite'\n",
    "\n",
    "            if self.check_twitter_exists() == True:\n",
    "                element = self.driver.find_element(By.CSS_SELECTOR, '.bt-link-extern[title^=\"Twitter\"]')\n",
    "                self.twitter_links = element.get_attribute('href')\n",
    "            else:\n",
    "                self.twitter_links = 'keine auf Bundestagsseite'\n",
    "\n",
    "            if self.check_instagram_exists() == True:\n",
    "                element = self.driver.find_element(By.CSS_SELECTOR, '.bt-link-extern[title^=\"Instagram\"]')\n",
    "                self.instagram_links = element.get_attribute('href')\n",
    "            else:\n",
    "                self.instagram_links = 'keine auf Bundestagsseite'\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Error occurred while processing profile link: {self.profile_link}.\\nError message: {str(e)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be79740a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
